{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM-VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import keras\n",
    "import codecs\n",
    "import csv\n",
    "import os\n",
    "import random\n",
    "\n",
    "from keras.layers import Bidirectional, Dense, Embedding, Input, Lambda, LSTM, RepeatVector, TimeDistributed, Layer, Activation, Dropout, Masking\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers.advanced_activations import ELU\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "from keras.models import Model\n",
    "from scipy import spatial\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import, clean, and encode input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BiH2][BiH2].C1(=CC=C(C=C1)(C(O)=O))(C(O)=O).COc1cc((C(O)=O))c(OC)cc1(C(O)=O) MOFid-v1.bew.cat0;comment\n"
     ]
    }
   ],
   "source": [
    "imported_data = pd.read_hdf(\"test_database.h5\")\n",
    "mofids = imported_data[\"MOFid\"].tolist()\n",
    "print(mofids[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BiH2][BiH2].C1(=CC=C(C=C1)(C(O)=O))(C(O)=O).COc1cc((C(O)=O))c(OC)cc1(C(O)=O).bew\n"
     ]
    }
   ],
   "source": [
    "def clean_inputs(mofid, cleaned_list):\n",
    "    for i in range(len(mofid)):\n",
    "        unclean = mofid[i]\n",
    "        spaces_removed = unclean.replace(' ','')\n",
    "        version_removed = spaces_removed.replace('MOFid-v1', '')\n",
    "        comment_removed = version_removed.replace(';comment', '')\n",
    "        clean = comment_removed.replace('.cat0', '')\n",
    "        cleaned_list.append(clean)\n",
    "\n",
    "clean_mofids = []\n",
    "clean_inputs(mofids, clean_mofids)\n",
    "max_mofid_length = max([len(mofid) for mofid in clean_mofids])\n",
    "print(clean_mofids[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 52 unique tokens\n",
      "{'UNK': 1, '(': 2, ')': 3, 'O': 4, 'C': 5, 'c': 6, '=': 7, '1': 8, '[': 9, ']': 10, '.': 11, 'n': 12, 'F': 13, 'N': 14, '2': 15, '+': 16, 'l': 17, '@': 18, 'u': 19, '3': 20, 'Z': 21, '#': 22, '4': 23, '6': 24, 'q': 25, 'o': 26, 'H': 27, 'd': 28, 'P': 29, 'i': 30, 'e': 31, '-': 32, 'R': 33, 'S': 34, '5': 35, 'b': 36, 'M': 37, 'z': 38, 'h': 39, 'p': 40, 'g': 41, 'r': 42, 's': 43, 'B': 44, 't': 45, 'T': 46, 'W': 47, 'w': 48, 'j': 49, 'a': 50, 'x': 51, 'y': 52}\n",
      "Shape of data tensor: (10651, 485)\n",
      "Shape of embedding weights tensor: (53, 52)\n"
     ]
    }
   ],
   "source": [
    "tk = Tokenizer(num_words=300, char_level=True, lower=False, oov_token='UNK')\n",
    "tk.fit_on_texts(clean_mofids)\n",
    "char_index = tk.word_index\n",
    "vocab_size = len(tk.word_index)\n",
    "index2char = {v: k for k, v in char_index.items()}\n",
    "\n",
    "print(\"Found %s unique tokens\" % vocab_size)\n",
    "print(char_index)\n",
    "\n",
    "full_sequences = tk.texts_to_sequences(clean_mofids)\n",
    "full_data_padded = pad_sequences(full_sequences, maxlen=max_mofid_length, padding='post')\n",
    "\n",
    "print('Shape of data tensor:', full_data_padded.shape)\n",
    "\n",
    "# separate off a validation set\n",
    "train_data = np.array(full_data_padded, dtype=\"int\")\n",
    "train_split, val_split = train_test_split(train_data, test_size = 0.2, random_state = 42)\n",
    "\n",
    "embedding_weights = []\n",
    "embedding_weights.append(np.zeros(vocab_size))\n",
    "\n",
    "for char, i in tk.word_index.items():\n",
    "    onehot = np.zeros(vocab_size)\n",
    "    onehot[i-1] = 1\n",
    "    embedding_weights.append(onehot)\n",
    "embedding_weights = np.array(embedding_weights)\n",
    "\n",
    "print('Shape of embedding weights tensor:',embedding_weights.shape)\n",
    "#print(embedding_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Vectorize the data.\n",
    "#input_texts = []\n",
    "#input_characters = set()\n",
    "#input_characters.add('UNK')\n",
    "\n",
    "#for i in range(len(clean_mofids)):\n",
    "#    input_text = clean_mofids[i]\n",
    "#    input_texts.append(input_text)\n",
    "#    for char in input_text:\n",
    "#        if char not in input_characters:\n",
    "#            input_characters.add(char)\n",
    "\n",
    "#input_characters = sorted(list(input_characters))\n",
    "#num_encoder_tokens = len(input_characters)\n",
    "#max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "\n",
    "#print(\"Number of samples:\", len(input_texts))\n",
    "#print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
    "#print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n",
    "\n",
    "#input_token_index = dict([(char, i+1) for i, char in enumerate(input_characters)])\n",
    "#print(input_token_index)\n",
    "\n",
    "#encoder_input_data = np.zeros(\n",
    "#    (len(input_texts), max_encoder_seq_length, num_encoder_tokens+1), dtype=\"int\"\n",
    "#)\n",
    "\n",
    "#print(input_texts[0])\n",
    "\n",
    "#for i, input_text in enumerate(input_texts):\n",
    "#    for t, char in enumerate(input_text):\n",
    "#        encoder_input_data[i, t, input_token_index[char]] = 1.0\n",
    "\n",
    "#np.set_printoptions(threshold=np.inf)\n",
    "#print(len(encoder_input_data[0][0]))\n",
    "#np.set_printoptions(threshold=1000)\n",
    "\n",
    "#train_data, validation_data = train_test_split(encoder_input_data, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A LSTM network expects the input to be in the form [samples, time steps, features] where samples is the number of data points we have, time steps is the number of time-dependent steps that are there in a single data point, features refers to the number of variables we have for the corresponding true value in Y. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the LSTM-VAE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 485) (71, 485, 53)\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 485)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 485, 52)      2756        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 106)          44944       embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "z_mean (Dense)                  (None, 26)           2782        bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "z_log_var (Dense)               (None, 26)           2782        bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 26)           0           z_mean[0][0]                     \n",
      "                                                                 z_log_var[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_2 (RepeatVector)  (None, 485, 26)      0           lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   (None, 485, 52)      16432       repeat_vector_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 485, 53)      2809        lstm_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "custom_variational_layer_2 (Cus [(None, 485), (None, 0           input_3[0][0]                    \n",
      "                                                                 dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 72,505\n",
      "Trainable params: 72,505\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "batch_size = 71\n",
    "max_len = max_mofid_length\n",
    "embedding_size = vocab_size\n",
    "intermediate_dim = vocab_size+1\n",
    "latent_dim = 26\n",
    "epsilon_std = 1.0\n",
    "kl_weight = 0.01\n",
    "num_sampled=500\n",
    "\n",
    "x = Input(shape=(max_len,))\n",
    "x_embed = Embedding(vocab_size+1, embedding_size, mask_zero=True, input_length=max_len, weights=[embedding_weights])(x)\n",
    "h = Bidirectional(LSTM(intermediate_dim, return_sequences=False, recurrent_dropout=0.2), merge_mode='concat')(x_embed)\n",
    "#h = Dropout(0.2)(h)\n",
    "#h = Dense(intermediate_dim, activation='linear')(h)\n",
    "#h = act(h)\n",
    "#h = Dropout(0.2)(h)\n",
    "z_mean = Dense(latent_dim, name=\"z_mean\")(h)\n",
    "z_log_var = Dense(latent_dim, name=\"z_log_var\")(h)\n",
    "\n",
    "\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = K.random_normal(shape=(batch_size, latent_dim), mean=0.,\n",
    "                              stddev=epsilon_std)\n",
    "    return z_mean + K.exp(z_log_var / 2) * epsilon\n",
    "\n",
    "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
    "\n",
    "repeated_context = RepeatVector(max_len)\n",
    "decoder_h = LSTM(vocab_size, return_sequences=True, recurrent_dropout=0.2)\n",
    "decoder_mean = Dense(vocab_size+1, activation='linear')#softmax is applied in the seq2seqloss by tf\n",
    "h_decoded = decoder_h(repeated_context(z))\n",
    "x_decoded_mean = decoder_mean(h_decoded)\n",
    "\n",
    "# placeholder loss\n",
    "def zero_loss(y_true, y_pred):\n",
    "    return K.zeros_like(y_pred)\n",
    "\n",
    "class CustomVariationalLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.is_placeholder = True\n",
    "        super(CustomVariationalLayer, self).__init__(**kwargs)\n",
    "        self.target_weights = tf.constant(np.ones((batch_size, max_len)), tf.float32)\n",
    "\n",
    "    def vae_loss(self, x, x_decoded_mean):\n",
    "        #xent_loss = K.sum(metrics.categorical_crossentropy(x, x_decoded_mean), axis=-1)\n",
    "        labels = tf.cast(x, tf.int32)\n",
    "        xent_loss = K.sum(tfa.seq2seq.sequence_loss(x_decoded_mean, labels, \n",
    "                                                     weights=self.target_weights,\n",
    "                                                     average_across_timesteps=False,\n",
    "                                                     average_across_batch=False), axis=-1)#,\n",
    "                                                     #softmax_loss_function=softmax_loss_f), axis=-1)#,\n",
    "        kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "        xent_loss = K.mean(xent_loss)\n",
    "        kl_loss = K.mean(kl_loss)\n",
    "        return K.mean(xent_loss + kl_weight * kl_loss)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = inputs[0]\n",
    "        x_decoded_mean = inputs[1]\n",
    "        print(x.shape, x_decoded_mean.shape)\n",
    "        loss = self.vae_loss(x, x_decoded_mean)\n",
    "        self.add_loss(loss, inputs=inputs)\n",
    "        # we don't use this output, but it has to have the correct shape:\n",
    "        return K.ones_like(x)\n",
    "\n",
    "def kl_loss(x, x_decoded_mean):\n",
    "    kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "    kl_loss = kl_weight * kl_loss\n",
    "    return kl_loss\n",
    "    \n",
    "loss_layer = CustomVariationalLayer()([x, x_decoded_mean])\n",
    "vae = Model(x, [loss_layer])\n",
    "opt = Adam(lr=0.01)\n",
    "\n",
    "vae.compile(optimizer='adam', loss=[zero_loss], metrics=[kl_loss])\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------epoch:  0 --------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adam/anaconda3/envs/ai3sd/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 71 samples, validate on 71 samples\n",
      "Epoch 1/1\n",
      "30/30 [==============================] - 74s 2s/step - loss: 1344.3059 - kl_loss: 0.3028 - val_loss: 27.4802 - val_kl_loss: 36.5073\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 27.48015, saving model to models/lstm_vae_attempt4_best_weights.h5\n",
      "0.001\n",
      "-------epoch:  1 --------\n",
      "Train on 71 samples, validate on 71 samples\n",
      "Epoch 1/1\n",
      "30/30 [==============================] - 65s 2s/step - loss: 754.7651 - kl_loss: 1.5212 - val_loss: 26.1243 - val_kl_loss: 50.0851\n",
      "\n",
      "Epoch 00001: val_loss improved from 27.48015 to 26.12427, saving model to models/lstm_vae_attempt4_best_weights.h5\n",
      "0.001\n",
      "-------epoch:  2 --------\n",
      "Train on 71 samples, validate on 71 samples\n",
      "Epoch 1/1\n",
      "30/30 [==============================] - 66s 2s/step - loss: 719.0480 - kl_loss: 1.7369 - val_loss: 26.3508 - val_kl_loss: 57.1215\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 26.12427\n",
      "0.001\n",
      "-------epoch:  3 --------\n",
      "Train on 71 samples, validate on 71 samples\n",
      "Epoch 1/1\n",
      "30/30 [==============================] - 68s 2s/step - loss: 641.3307 - kl_loss: 1.9984 - val_loss: 24.4935 - val_kl_loss: 67.9066\n",
      "\n",
      "Epoch 00001: val_loss improved from 26.12427 to 24.49352, saving model to models/lstm_vae_attempt4_best_weights.h5\n",
      "0.001\n",
      "-------epoch:  4 --------\n",
      "Train on 71 samples, validate on 71 samples\n",
      "Epoch 1/1\n",
      "30/30 [==============================] - 68s 2s/step - loss: 631.5462 - kl_loss: 2.4716 - val_loss: 21.1474 - val_kl_loss: 79.7396\n",
      "\n",
      "Epoch 00001: val_loss improved from 24.49352 to 21.14740, saving model to models/lstm_vae_attempt4_best_weights.h5\n",
      "0.001\n",
      "-------epoch:  5 --------\n",
      "Train on 71 samples, validate on 71 samples\n",
      "Epoch 1/1\n",
      "30/30 [==============================] - 68s 2s/step - loss: 586.2734 - kl_loss: 2.8374 - val_loss: 16.9330 - val_kl_loss: 87.7738\n",
      "\n",
      "Epoch 00001: val_loss improved from 21.14740 to 16.93298, saving model to models/lstm_vae_attempt4_best_weights.h5\n",
      "0.001\n",
      "-------epoch:  6 --------\n",
      "Train on 71 samples, validate on 71 samples\n",
      "Epoch 1/1\n",
      "30/30 [==============================] - 66s 2s/step - loss: 558.6539 - kl_loss: 3.0628 - val_loss: 18.0067 - val_kl_loss: 91.3001\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 16.93298\n",
      "0.001\n",
      "-------epoch:  7 --------\n",
      "Train on 71 samples, validate on 71 samples\n",
      "Epoch 1/1\n",
      "30/30 [==============================] - 66s 2s/step - loss: 536.2977 - kl_loss: 3.0690 - val_loss: 19.0519 - val_kl_loss: 92.1650\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 16.93298\n",
      "0.001\n",
      "-------epoch:  8 --------\n",
      "Train on 71 samples, validate on 71 samples\n",
      "Epoch 1/1\n",
      "30/30 [==============================] - 67s 2s/step - loss: 576.0098 - kl_loss: 3.0699 - val_loss: 16.6017 - val_kl_loss: 90.5463\n",
      "\n",
      "Epoch 00001: val_loss improved from 16.93298 to 16.60166, saving model to models/lstm_vae_attempt4_best_weights.h5\n",
      "0.001\n",
      "-------epoch:  9 --------\n",
      "Train on 71 samples, validate on 71 samples\n",
      "Epoch 1/1\n",
      "30/30 [==============================] - 67s 2s/step - loss: 528.7791 - kl_loss: 3.0291 - val_loss: 17.0770 - val_kl_loss: 90.2144\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 16.60166\n",
      "0.001\n",
      "-------epoch:  10 --------\n",
      "Train on 71 samples, validate on 71 samples\n",
      "Epoch 1/1\n",
      "30/30 [==============================] - 68s 2s/step - loss: 497.9571 - kl_loss: 2.9812 - val_loss: 14.7221 - val_kl_loss: 88.5576\n",
      "\n",
      "Epoch 00001: val_loss improved from 16.60166 to 14.72211, saving model to models/lstm_vae_attempt4_best_weights.h5\n",
      "0.001\n",
      "-------epoch:  11 --------\n",
      "Train on 71 samples, validate on 71 samples\n",
      "Epoch 1/1\n",
      " 9/30 [========>.....................] - ETA: 37s - loss: 452.2913 - kl_loss: 2.9638"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-6ac4285457c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m                       \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                       \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_batches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_batches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m                       callbacks=[checkpointer])\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;31m#K.set_value(vae.optimizer.lr, 0.01)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai3sd/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/ai3sd/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    150\u001b[0m                 \u001b[0mbatch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'batch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstep_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'begin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfit_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai3sd/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3727\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3729\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai3sd/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \"\"\"\n\u001b[0;32m-> 1551\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai3sd/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1591\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai3sd/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ai3sd/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/ai3sd/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "attempt = 4\n",
    "\n",
    "def create_model_checkpoint(dir, model_name):\n",
    "    filepath = dir + '/' + model_name + \".h5\" \n",
    "    directory = os.path.dirname(filepath)\n",
    "    try:\n",
    "        os.stat(directory)\n",
    "    except:\n",
    "        os.mkdir(directory)\n",
    "    checkpointer = ModelCheckpoint(filepath=filepath, verbose=1, save_best_only=True)\n",
    "    return checkpointer\n",
    "\n",
    "checkpointer = create_model_checkpoint('models', f'lstm_vae_attempt{attempt}_best_weights')\n",
    "\n",
    "def batch_generator(dataset, chunk_size, epochs):\n",
    "    train_batches = []\n",
    "    for i in range(epochs):\n",
    "        epoch = i\n",
    "        train_batch = dataset[(epoch*chunk_size):((epoch+1)*chunk_size)]\n",
    "        train_batches.append(train_batch)\n",
    "    return train_batches\n",
    "\n",
    "def val_batch_generator(dataset, chunk_size, epochs):\n",
    "    val_batches = []\n",
    "    for i in range(epochs):\n",
    "        randint = random.randint(1, (len(dataset)-chunk_size))\n",
    "        val_batch = dataset[(randint):(randint+chunk_size)]\n",
    "        val_batches.append(val_batch)\n",
    "    return val_batches\n",
    "\n",
    "n_epoch=120\n",
    "\n",
    "train_batches = batch_generator(dataset=train_split, chunk_size=batch_size, epochs=n_epoch)\n",
    "val_batches = val_batch_generator(dataset=val_split, chunk_size=batch_size, epochs=n_epoch)\n",
    "\n",
    "#n_steps =  int(len(batches[0])/batch_size)\n",
    "n_steps = 30\n",
    "\n",
    "for counter in range(n_epoch):\n",
    "    print('-------epoch: ',counter,'--------')\n",
    "    vae.fit(train_batches[counter], train_batches[counter],\n",
    "                      shuffle=True,\n",
    "                      steps_per_epoch=n_steps,\n",
    "                      epochs=1,\n",
    "                      validation_data=(val_batches[counter], val_batches[counter]), validation_steps=n_steps,\n",
    "                      callbacks=[checkpointer])\n",
    "    print(K.eval(vae.optimizer.lr))\n",
    "    #K.set_value(vae.optimizer.lr, 0.01)\n",
    "\n",
    "vae.save(f'models/lstm_vae_attempt{attempt}.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 485)               0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 485, 52)           2756      \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 106)               44944     \n",
      "_________________________________________________________________\n",
      "z_mean (Dense)               (None, 26)                2782      \n",
      "=================================================================\n",
      "Total params: 50,482\n",
      "Trainable params: 50,482\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vae.load_weights('models/lstm_vae_best_weights.h5')\n",
    "\n",
    "# build a model to project sentences on the latent space\n",
    "encoder = Model(x, z_mean)\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 26)                0         \n",
      "_________________________________________________________________\n",
      "repeat_vector_2 (RepeatVecto (None, 485, 26)           0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 485, 52)           16432     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 485, 53)           2809      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 485, 53)           0         \n",
      "=================================================================\n",
      "Total params: 19,241\n",
      "Trainable params: 19,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build a generator that can sample sentences from the learned distribution\n",
    "decoder_input = Input(shape=(latent_dim,))\n",
    "_h_decoded = decoder_h(repeated_context(decoder_input))\n",
    "_x_decoded_mean = decoder_mean(_h_decoded)\n",
    "_x_decoded_mean = Activation('softmax')(_x_decoded_mean)\n",
    "generator = Model(decoder_input, _x_decoded_mean)\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9 21 10 10 10 10 10  9  9  9  9  9  9  9  9  9 10 10 10 10  5  5  5  5\n",
      "  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  5  2  2\n",
      "  2  2  2  2  2  2  2  2  2  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  3  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0]\n",
      "Reconstructed MOFid:  [Z]]]]][[[[[[[[[]]]]CCCCCCCCCCCCCCCCCCCCCCCCCC((((((((((())))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\n"
     ]
    }
   ],
   "source": [
    "index2char = {v: k for k, v in char_index.items()}\n",
    "index2char[0] = '0' # padding value\n",
    "\n",
    "mofid_index = 20\n",
    "mofid_encoded = encoder.predict(val_split)\n",
    "x_test_reconstructed = generator.predict(mofid_encoded, batch_size = 1)\n",
    "reconstructed_indexes = np.apply_along_axis(np.argmax, 1, x_test_reconstructed[0])\n",
    "\n",
    "print(reconstructed_indexes)\n",
    "\n",
    "word_list = list(np.vectorize(index2char.get)(reconstructed_indexes))\n",
    "word_list = ''.join(map(str, word_list))\n",
    "print('Reconstructed MOFid: ', word_list)\n",
    "\n",
    "#original_mofid = []\n",
    "#for i in range(len(validation_data[mofid_index])):\n",
    "#    original_mofid.append(index2char[np.argmax(random_val[mofid_index][i])])\n",
    "#original_sent = list(np.vectorize(index2word.get)(random_val[mofid_index]))\n",
    "#original_mofid = ''.join(map(str, original_mofid))\n",
    "#print('Original MOFid: ',original_mofid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "If evaluating from data tensors, you should specify the `steps` argument.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-5aab75b6aaa5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#model = keras.models.load_model('models/lstm_vae_attempt3.h5',\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#                                custom_objects={'CustomVariationalLayer': CustomVariationalLayer})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/ai3sd/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1340\u001b[0m         \u001b[0;31m# Case 2: Symbolic tensors or Numpy array-like.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msteps\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1342\u001b[0;31m             raise ValueError('If evaluating from data tensors, '\n\u001b[0m\u001b[1;32m   1343\u001b[0m                              \u001b[0;34m'you should specify the `steps` '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1344\u001b[0m                              'argument.')\n",
      "\u001b[0;31mValueError\u001b[0m: If evaluating from data tensors, you should specify the `steps` argument."
     ]
    }
   ],
   "source": [
    "#model = keras.models.load_model('models/lstm_vae_attempt3.h5', \n",
    "#                                custom_objects={'CustomVariationalLayer': CustomVariationalLayer})\n",
    "vae.evaluate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
